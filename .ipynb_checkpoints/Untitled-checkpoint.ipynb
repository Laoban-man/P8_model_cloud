{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512a8172-89d4-45bb-b3a4-1393c3fc29c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import ArrayType, DoubleType, IntegerType, FloatType\n",
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler, PCA\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "from typing import Type, Any, Callable, Union, List, Dict, Optional, cast\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict \n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import boto3\n",
    "from torchvision.models.vgg import *\n",
    "from torchvision.models.vgg import model_urls, cfgs\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # Extract VGG-16 Feature Layers\n",
    "        self.features = list(model.features)\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        # Extract VGG-16 Average Pooling Layer\n",
    "        self.pooling = model.avgpool\n",
    "        # Convert the image into one-dimensional vector\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Extract the first part of fully-connected layer from VGG16\n",
    "        self.fc = model.classifier[0]\n",
    "  \n",
    "    def forward(self, x):\n",
    "        # It will take the input 'x' until it returns the feature vector called 'out'\n",
    "        out = self.features(x)\n",
    "        out = self.pooling(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc(out) \n",
    "        return out \n",
    "\n",
    "# Initialize the model\n",
    "model = models.vgg16(pretrained=True)\n",
    "new_model = FeatureExtractor(model)\n",
    "# Change the device to GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "new_model = new_model.to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToPILImage(),\n",
    "  transforms.CenterCrop(512),\n",
    "  transforms.Resize(100),\n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "def extractfeature(path,transform,new_model):\n",
    "    path=path[5:]\n",
    "    img = cv2.imread(path)\n",
    "    # Transform the image\n",
    "    img = transform(img)\n",
    "    # Reshape the image. PyTorch model reads 4-dimensional tensor\n",
    "    # [batch_size, channels, width, height]\n",
    "    img = img.reshape(1, 3, 100, 100)\n",
    "    img = img.to(device)\n",
    "    # We only extract features, so we don't need gradient\n",
    "    with torch.no_grad():\n",
    "        # Extract the feature from the image\n",
    "        feature = new_model(img)\n",
    "        # Convert to NumPy Array, Reshape it, and save it to features variable\n",
    "    temp=feature.cpu().detach().numpy().reshape(-1)\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e5a2f40-c577-42b2-b45e-c733060949d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local\").appName(\"SparkByExamples.com\").getOrCreate()\n",
    ")\n",
    "\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"AKIA3FBVFAGLF7WW6BWD\")\n",
    "spark._jsc.hadoopConfiguration().set(\n",
    "    \"fs.s3a.secret.key\", \"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\"\n",
    ")\n",
    "spark._jsc.hadoopConfiguration().set(\n",
    "    \"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\"\n",
    ")\n",
    "spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "spark._jsc.hadoopConfiguration().set(\n",
    "    \"fs.s3a.aws.credentials.provider\",\n",
    "    \"org.apache.hadoop.fs.s3a.BasicAWSCredentialsProvider\",\n",
    ")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"eu-west-3.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2ac1c6-3170-4792-ad2a-189122b9b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"../data/fruits/fruits-360_dataset/fruits-360/Training/Apricot/*\"\n",
    "df = spark.read.format(\"image\").load(data_url)\n",
    "feat = F.udf(lambda x: DenseVector(extractfeature(x,transform=transform,new_model=new_model)), VectorUDT())\n",
    "df = df.withColumn(\"vecs\", feat(\"image.origin\"))\n",
    "data = df.select(\"vecs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "663fecc0-dcf6-49f8-8fc3-5f5d667ba585",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o433.fit.\n: java.lang.OutOfMemoryError: Java heap space\n\tat breeze.linalg.svd$.breeze$linalg$svd$$doSVD_Double(svd.scala:94)\n\tat breeze.linalg.svd$Svd_DM_Impl$.apply(svd.scala:36)\n\tat breeze.linalg.svd$Svd_DM_Impl$.apply(svd.scala:35)\n\tat breeze.generic.UFunc.apply(UFunc.scala:46)\n\tat breeze.generic.UFunc.apply$(UFunc.scala:45)\n\tat breeze.linalg.svd$.apply(svd.scala:21)\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computePrincipalComponentsAndExplainedVariance(RowMatrix.scala:481)\n\tat org.apache.spark.mllib.feature.PCA.fit(PCA.scala:65)\n\tat org.apache.spark.ml.feature.PCA.fit(PCA.scala:93)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-3b4646dbbe15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaledData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"scaledvecs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pcavecs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaledData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mreduced_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaledData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pcavecs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/vivadata/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/vivadata/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/vivadata/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/vivadata/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/vivadata/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/vivadata/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o433.fit.\n: java.lang.OutOfMemoryError: Java heap space\n\tat breeze.linalg.svd$.breeze$linalg$svd$$doSVD_Double(svd.scala:94)\n\tat breeze.linalg.svd$Svd_DM_Impl$.apply(svd.scala:36)\n\tat breeze.linalg.svd$Svd_DM_Impl$.apply(svd.scala:35)\n\tat breeze.generic.UFunc.apply(UFunc.scala:46)\n\tat breeze.generic.UFunc.apply$(UFunc.scala:45)\n\tat breeze.linalg.svd$.apply(svd.scala:21)\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computePrincipalComponentsAndExplainedVariance(RowMatrix.scala:481)\n\tat org.apache.spark.mllib.feature.PCA.fit(PCA.scala:65)\n\tat org.apache.spark.ml.feature.PCA.fit(PCA.scala:93)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(inputCol=\"vecs\", outputCol=\"scaledvecs\")\n",
    "scaledData = scaler.fit(data).transform(data)\n",
    "pca = PCA(k=10, inputCol=\"scaledvecs\", outputCol=\"pcavecs\")\n",
    "model = pca.fit(scaledData)\n",
    "reduced_data = model.transform(scaledData).select(\"pcavecs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12056a8-df39-4522-8a75-e8e4b7a3a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc213fc-5903-4b3a-bef6-11c7d99d835e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.6019713878631592, -3.5101022720336914, 1.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.5929287672042847, -3.5260071754455566, 0.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.609989881515503, -3.4946999549865723, 1.240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.6050442457199097, -3.526664972305298, 1.183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.5339109897613525, -3.5794451236724854, 0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>[1.7248787879943848, -2.0906875133514404, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>[1.6911070346832275, -2.0984740257263184, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>[1.6200666427612305, -2.216568946838379, 0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>[1.6160438060760498, -2.1579718589782715, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>[1.619590163230896, -2.1844053268432617, 0.062...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vecs\n",
       "0    [1.6019713878631592, -3.5101022720336914, 1.05...\n",
       "1    [1.5929287672042847, -3.5260071754455566, 0.96...\n",
       "2    [1.609989881515503, -3.4946999549865723, 1.240...\n",
       "3    [1.6050442457199097, -3.526664972305298, 1.183...\n",
       "4    [1.5339109897613525, -3.5794451236724854, 0.89...\n",
       "..                                                 ...\n",
       "487  [1.7248787879943848, -2.0906875133514404, 0.13...\n",
       "488  [1.6911070346832275, -2.0984740257263184, 0.14...\n",
       "489  [1.6200666427612305, -2.216568946838379, 0.062...\n",
       "490  [1.6160438060760498, -2.1579718589782715, 0.05...\n",
       "491  [1.619590163230896, -2.1844053268432617, 0.062...\n",
       "\n",
       "[492 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca107ea1-d073-4a1b-b1a5-71b29b9ed661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "df = spark.read.load(\"part-00000-5054f0dd-0b92-4932-b2e1-c3ecd52c90b5-c000.snappy.parquet\")\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3230b7-6996-423b-9cd8-901f10c5462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.6019713878631592, -3.510100841522217, 1.050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.592928409576416, -3.5260071754455566, 0.964...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.6099903583526611, -3.4947004318237305, 1.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.6050448417663574, -3.5266647338867188, 1.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.5339117050170898, -3.5794458389282227, 0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>[1.7248785495758057, -2.0906877517700195, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>[1.6911072731018066, -2.0984749794006348, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>[1.6200671195983887, -2.2165684700012207, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>[1.616042971611023, -2.1579718589782715, 0.057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>[1.6195900440216064, -2.184403896331787, 0.062...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vecs\n",
       "0    [1.6019713878631592, -3.510100841522217, 1.050...\n",
       "1    [1.592928409576416, -3.5260071754455566, 0.964...\n",
       "2    [1.6099903583526611, -3.4947004318237305, 1.24...\n",
       "3    [1.6050448417663574, -3.5266647338867188, 1.18...\n",
       "4    [1.5339117050170898, -3.5794458389282227, 0.89...\n",
       "..                                                 ...\n",
       "487  [1.7248785495758057, -2.0906877517700195, 0.13...\n",
       "488  [1.6911072731018066, -2.0984749794006348, 0.14...\n",
       "489  [1.6200671195983887, -2.2165684700012207, 0.06...\n",
       "490  [1.616042971611023, -2.1579718589782715, 0.057...\n",
       "491  [1.6195900440216064, -2.184403896331787, 0.062...\n",
       "\n",
       "[492 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
